{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58766b6",
   "metadata": {},
   "source": [
    "********Generate Dataset********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17530eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 11)\n",
      "is_fraud\n",
      "0    0.96468\n",
      "1    0.03532\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "\n",
    "# -----------------------\n",
    "# Setup\n",
    "# -----------------------\n",
    "fake = Faker()\n",
    "np.random.seed(42)\n",
    "Faker.seed(42)\n",
    "\n",
    "ROWS = 50000\n",
    "FRAUD_RATE = 0.035\n",
    "\n",
    "#Ye merchant, transaction and country teeno hee repeat hoti hai aur unka distribution bhi fix hai. Isliye unko loop ke bahar define kar diya hai.\n",
    "merchant_categories = [\n",
    "    \"Grocery\", \"Fuel\", \"Electronics\",\n",
    "    \"Travel\", \"Dining\", \"E-commerce\"\n",
    "]\n",
    "transaction_types = [\"Online\", \"POS\", \"ATM\"]\n",
    "countries = [\"India\", \"USA\", \"UK\", \"UAE\", \"Singapore\"]\n",
    "\n",
    "records = [] #ye empty list hai jisme data store hoga.\n",
    "\n",
    "# -----------------------\n",
    "# Data Generation Loop\n",
    "# -----------------------\n",
    "for _ in range(ROWS):\n",
    "\n",
    "    # Fraud flag\n",
    "    is_fraud = np.random.choice([0, 1], p=[1 - FRAUD_RATE, FRAUD_RATE])\n",
    "\n",
    "    # Transaction amount\n",
    "    amount = (\n",
    "        np.random.normal(2500, 1200)\n",
    "        if is_fraud == 0\n",
    "        else np.random.uniform(8000, 50000)\n",
    "    )\n",
    "\n",
    "    # Time gap (velocity)\n",
    "    hours_gap = (\n",
    "        np.random.exponential(10)\n",
    "        if is_fraud == 0\n",
    "        else np.random.uniform(0.1, 1.5)\n",
    "    )\n",
    "\n",
    "    # Foreign transaction flag\n",
    "    foreign_txn = (\n",
    "        np.random.choice([0, 1], p=[0.85, 0.15])\n",
    "        if is_fraud == 0\n",
    "        else np.random.choice([0, 1], p=[0.3, 0.7])\n",
    "    )\n",
    "\n",
    "    # Risk score\n",
    "    risk_score = round(\n",
    "        (amount / 50000) * 0.4 +\n",
    "        (1 / max(hours_gap, 0.1)) * 0.4 +\n",
    "        foreign_txn * 0.2,\n",
    "        2\n",
    "    )\n",
    "\n",
    "    # Append record\n",
    "    records.append({\n",
    "        \"transaction_id\": fake.uuid4(),\n",
    "        \"transaction_date\": fake.date_time_between(\"-6M\", \"now\"),\n",
    "        \"customer_id\": f\"CUST-{np.random.randint(10000, 99999)}\",\n",
    "        \"merchant_category\": np.random.choice(merchant_categories),\n",
    "        \"transaction_amount\": round(max(amount, 50), 2),\n",
    "        \"transaction_type\": np.random.choice(transaction_types),\n",
    "        \"merchant_country\": np.random.choice(countries),\n",
    "        \"hours_since_last_txn\": round(hours_gap, 2),\n",
    "        \"is_foreign_transaction\": foreign_txn,\n",
    "        \"fraud_risk_score\": risk_score,\n",
    "        \"is_fraud\": is_fraud\n",
    "    })\n",
    "\n",
    "# -----------------------\n",
    "# Create DataFrame & Save\n",
    "# -----------------------\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(\"transactions.csv\", index=False)\n",
    "\n",
    "print(df.shape)\n",
    "print(df[\"is_fraud\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab620cb",
   "metadata": {},
   "source": [
    "*Customer Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf711f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38413, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>age</th>\n",
       "      <th>income_band</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>customer_since</th>\n",
       "      <th>home_country</th>\n",
       "      <th>risk_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUST-54131</td>\n",
       "      <td>56</td>\n",
       "      <td>Medium</td>\n",
       "      <td>564</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>USA</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUST-93104</td>\n",
       "      <td>38</td>\n",
       "      <td>Low</td>\n",
       "      <td>514</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>India</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUST-28431</td>\n",
       "      <td>41</td>\n",
       "      <td>Low</td>\n",
       "      <td>451</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>USA</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUST-90038</td>\n",
       "      <td>19</td>\n",
       "      <td>Medium</td>\n",
       "      <td>707</td>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>India</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUST-33483</td>\n",
       "      <td>38</td>\n",
       "      <td>Medium</td>\n",
       "      <td>607</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>India</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  age income_band  credit_score customer_since home_country  \\\n",
       "0  CUST-54131   56      Medium           564     2020-02-17          USA   \n",
       "1  CUST-93104   38         Low           514     2020-03-06        India   \n",
       "2  CUST-28431   41         Low           451     2020-01-26          USA   \n",
       "3  CUST-90038   19      Medium           707     2022-07-07        India   \n",
       "4  CUST-33483   38      Medium           607     2018-09-04        India   \n",
       "\n",
       "  risk_segment  \n",
       "0       Medium  \n",
       "1         High  \n",
       "2         High  \n",
       "3          Low  \n",
       "4       Medium  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "np.random.seed(42)\n",
    "\n",
    "# --------------------------------\n",
    "# Step 1: Transactions se unique customer_id nikaalna\n",
    "# --------------------------------\n",
    "# Kyun: Customers dataset ko transactions se link karna hai\n",
    "customer_ids = df[\"customer_id\"].unique()\n",
    "\n",
    "# --------------------------------\n",
    "# Step 2: Empty list banani (records store karne ke liye)\n",
    "# --------------------------------\n",
    "customer_records = []\n",
    "\n",
    "# --------------------------------\n",
    "# Step 3: Har customer ke liye profile banana\n",
    "# --------------------------------\n",
    "for cust_id in customer_ids:\n",
    "\n",
    "    # Age generate karna (realistic banking range)\n",
    "    age = np.random.randint(18, 70)\n",
    "\n",
    "    # Income band decide karna (simple segmentation)\n",
    "    income_band = np.random.choice(\n",
    "        [\"Low\", \"Medium\", \"High\"],\n",
    "        p=[0.4, 0.4, 0.2]   # zyada log low/medium income hote hain\n",
    "    )\n",
    "\n",
    "    # Credit score generate karna\n",
    "    credit_score = (\n",
    "        np.random.randint(300, 600) if income_band == \"Low\"\n",
    "        else np.random.randint(550, 750) if income_band == \"Medium\"\n",
    "        else np.random.randint(700, 900)\n",
    "    )\n",
    "    # Low income → low credit score, High income → better score\n",
    "\n",
    "    # Customer since date (kab se bank ka customer hai)\n",
    "    customer_since = fake.date_between(start_date=\"-10y\", end_date=\"-1y\")\n",
    "\n",
    "    # Home country\n",
    "    home_country = np.random.choice(\n",
    "        [\"India\", \"USA\", \"UK\", \"UAE\", \"Singapore\"],\n",
    "        p=[0.6, 0.15, 0.1, 0.1, 0.05]\n",
    "    )\n",
    "\n",
    "    # Risk segment derive karna (business-friendly label)\n",
    "    if credit_score < 550:\n",
    "        risk_segment = \"High\"\n",
    "    elif credit_score < 700:\n",
    "        risk_segment = \"Medium\"\n",
    "    else:\n",
    "        risk_segment = \"Low\"\n",
    "\n",
    "    # --------------------------------\n",
    "    # Step 4: Customer record append karna\n",
    "    # --------------------------------\n",
    "    customer_records.append({\n",
    "        \"customer_id\": cust_id,\n",
    "        \"age\": age,\n",
    "        \"income_band\": income_band,\n",
    "        \"credit_score\": credit_score,\n",
    "        \"customer_since\": customer_since,\n",
    "        \"home_country\": home_country,\n",
    "        \"risk_segment\": risk_segment\n",
    "    })\n",
    "\n",
    "# --------------------------------\n",
    "# Step 5: DataFrame banana\n",
    "# --------------------------------\n",
    "customers_df = pd.DataFrame(customer_records)\n",
    "\n",
    "# --------------------------------\n",
    "# Step 6: CSV me save karna\n",
    "# --------------------------------\n",
    "customers_df.to_csv(\"customers.csv\", index=False)\n",
    "\n",
    "# Quick sanity check\n",
    "print(customers_df.shape)\n",
    "customers_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069ad65",
   "metadata": {},
   "source": [
    "*Merchants Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "481a3b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_category</th>\n",
       "      <th>merchant_country</th>\n",
       "      <th>avg_transaction_value</th>\n",
       "      <th>merchant_risk_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2185.43</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Travel</td>\n",
       "      <td>India</td>\n",
       "      <td>3193.96</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuel</td>\n",
       "      <td>UAE</td>\n",
       "      <td>761.38</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E-commerce</td>\n",
       "      <td>India</td>\n",
       "      <td>3686.33</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dining</td>\n",
       "      <td>India</td>\n",
       "      <td>4245.99</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  merchant_category merchant_country  avg_transaction_value  \\\n",
       "0       Electronics        Singapore                2185.43   \n",
       "1            Travel            India                3193.96   \n",
       "2              Fuel              UAE                 761.38   \n",
       "3        E-commerce            India                3686.33   \n",
       "4            Dining            India                4245.99   \n",
       "\n",
       "   merchant_risk_score  \n",
       "0                 0.56  \n",
       "1                 0.45  \n",
       "2                 0.33  \n",
       "3                 0.83  \n",
       "4                 0.58  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# --------------------------------\n",
    "# Step 1: Transactions se unique merchant_category nikaalna\n",
    "# --------------------------------\n",
    "# Kyun: Merchants ko transactions se link karna hai\n",
    "merchant_categories = df[\"merchant_category\"].unique()\n",
    "\n",
    "# --------------------------------\n",
    "# Step 2: Empty list banani (merchant records store karne ke liye)\n",
    "# --------------------------------\n",
    "merchant_records = []\n",
    "\n",
    "# --------------------------------\n",
    "# Step 3: Har merchant category ke liye profile banana\n",
    "# --------------------------------\n",
    "for category in merchant_categories:\n",
    "\n",
    "    # Average transaction value (category-specific behavior)\n",
    "    avg_txn_value = np.random.uniform(500, 5000)\n",
    "    # Grocery/Fuel jaise categories lower, Travel/Electronics higher ho sakte hain\n",
    "\n",
    "    # Merchant country (mostly domestic, thoda foreign mix)\n",
    "    merchant_country = np.random.choice(\n",
    "        [\"India\", \"USA\", \"UK\", \"UAE\", \"Singapore\"],\n",
    "        p=[0.55, 0.15, 0.1, 0.1, 0.1]\n",
    "    )\n",
    "\n",
    "    # Merchant risk score (0–1 scale)\n",
    "    merchant_risk_score = round(\n",
    "        (avg_txn_value / 5000) * 0.6 +\n",
    "        np.random.uniform(0, 0.4),\n",
    "        2\n",
    "    )\n",
    "    # High avg value + randomness = higher risk\n",
    "\n",
    "    # --------------------------------\n",
    "    # Step 4: Merchant record append karna\n",
    "    # --------------------------------\n",
    "    merchant_records.append({\n",
    "        \"merchant_category\": category,\n",
    "        \"merchant_country\": merchant_country,\n",
    "        \"avg_transaction_value\": round(avg_txn_value, 2),\n",
    "        \"merchant_risk_score\": merchant_risk_score\n",
    "    })\n",
    "\n",
    "# --------------------------------\n",
    "# Step 5: DataFrame banana\n",
    "# --------------------------------\n",
    "merchants_df = pd.DataFrame(merchant_records)\n",
    "\n",
    "# --------------------------------\n",
    "# Step 6: CSV me save karna\n",
    "# --------------------------------\n",
    "merchants_df.to_csv(\"merchants.csv\", index=False)\n",
    "\n",
    "# Quick sanity check\n",
    "print(merchants_df.shape)\n",
    "merchants_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f356f29",
   "metadata": {},
   "source": [
    "*Left-Join*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c878032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         transaction_id    transaction_date customer_id  \\\n",
      "0  bdd640fb-0667-4ad1-9c80-317fa3b1799d 2025-08-23 22:53:27  CUST-54131   \n",
      "1  bc8960a9-23b8-41e9-b924-56de3eb13b90 2025-07-21 10:49:24  CUST-93104   \n",
      "2  8b9d2434-e465-4150-bd9c-66b3ad3c2d6d 2025-07-18 10:19:32  CUST-28431   \n",
      "3  07a0ca6e-0822-48f3-ac03-1199972a8469 2025-07-19 17:48:46  CUST-90038   \n",
      "4  9a1de644-815e-46d1-bb8f-aa1837f8a88b 2025-07-06 16:49:40  CUST-33483   \n",
      "\n",
      "  merchant_category  transaction_amount transaction_type merchant_country  \\\n",
      "0       Electronics             1165.74              POS        Singapore   \n",
      "1            Travel            42962.59              POS        Singapore   \n",
      "2            Travel             2882.68              ATM               UK   \n",
      "3              Fuel             2470.65           Online              UAE   \n",
      "4            Travel             2926.66           Online               UK   \n",
      "\n",
      "   hours_since_last_txn  is_foreign_transaction  fraud_risk_score  is_fraud  \\\n",
      "0                  1.70                       0              0.25         0   \n",
      "1                  0.40                       0              1.35         1   \n",
      "2                  3.44                       0              0.14         0   \n",
      "3                 19.66                       0              0.04         0   \n",
      "4                  4.87                       0              0.11         0   \n",
      "\n",
      "   age income_band  credit_score customer_since home_country risk_segment  \n",
      "0   56      Medium           564     2020-02-17          USA       Medium  \n",
      "1   38         Low           514     2020-03-06        India         High  \n",
      "2   41         Low           451     2020-01-26          USA         High  \n",
      "3   19      Medium           707     2022-07-07        India          Low  \n",
      "4   38      Medium           607     2018-09-04        India       Medium  \n",
      "(50000, 17)\n",
      "                         transaction_id    transaction_date customer_id  \\\n",
      "0  bdd640fb-0667-4ad1-9c80-317fa3b1799d 2025-08-23 22:53:27  CUST-54131   \n",
      "1  bc8960a9-23b8-41e9-b924-56de3eb13b90 2025-07-21 10:49:24  CUST-93104   \n",
      "2  8b9d2434-e465-4150-bd9c-66b3ad3c2d6d 2025-07-18 10:19:32  CUST-28431   \n",
      "3  07a0ca6e-0822-48f3-ac03-1199972a8469 2025-07-19 17:48:46  CUST-90038   \n",
      "4  9a1de644-815e-46d1-bb8f-aa1837f8a88b 2025-07-06 16:49:40  CUST-33483   \n",
      "\n",
      "  merchant_category  transaction_amount transaction_type merchant_country_x  \\\n",
      "0       Electronics             1165.74              POS          Singapore   \n",
      "1            Travel            42962.59              POS          Singapore   \n",
      "2            Travel             2882.68              ATM                 UK   \n",
      "3              Fuel             2470.65           Online                UAE   \n",
      "4            Travel             2926.66           Online                 UK   \n",
      "\n",
      "   hours_since_last_txn  is_foreign_transaction  fraud_risk_score  is_fraud  \\\n",
      "0                  1.70                       0              0.25         0   \n",
      "1                  0.40                       0              1.35         1   \n",
      "2                  3.44                       0              0.14         0   \n",
      "3                 19.66                       0              0.04         0   \n",
      "4                  4.87                       0              0.11         0   \n",
      "\n",
      "   age income_band  credit_score customer_since home_country risk_segment  \\\n",
      "0   56      Medium           564     2020-02-17          USA       Medium   \n",
      "1   38         Low           514     2020-03-06        India         High   \n",
      "2   41         Low           451     2020-01-26          USA         High   \n",
      "3   19      Medium           707     2022-07-07        India          Low   \n",
      "4   38      Medium           607     2018-09-04        India       Medium   \n",
      "\n",
      "  merchant_country_y  avg_transaction_value  merchant_risk_score  \n",
      "0          Singapore                2185.43                 0.56  \n",
      "1              India                3193.96                 0.45  \n",
      "2              India                3193.96                 0.45  \n",
      "3                UAE                 761.38                 0.33  \n",
      "4              India                3193.96                 0.45  \n",
      "(50000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Ensure transactions dataframe is available (cell execution order may vary)\n",
    "try:\n",
    "    df  # if df exists, use it\n",
    "except NameError:\n",
    "    # load from CSV created earlier\n",
    "    df = pd.read_csv(\"transactions.csv\", parse_dates=[\"transaction_date\"])\n",
    "\n",
    "# Ensure customers_df is available\n",
    "try:\n",
    "    customers_df\n",
    "except NameError:\n",
    "    customers_df = pd.read_csv(\"customers.csv\", parse_dates=[\"customer_since\"])\n",
    "\n",
    "# Ensure merchants_df is available\n",
    "try:\n",
    "    merchants_df\n",
    "except NameError:\n",
    "    merchants_df = pd.read_csv(\"merchants.csv\")\n",
    "\n",
    "# LEFT JOIN because every transaction is important\n",
    "df_txn_customer = pd.merge(\n",
    "    df,\n",
    "    customers_df,\n",
    "    on=\"customer_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Check output\n",
    "print(df_txn_customer.head())\n",
    "print(df_txn_customer.shape)\n",
    "\n",
    "# join with merchants on the correct key\n",
    "final_df = pd.merge(\n",
    "    df_txn_customer,\n",
    "    merchants_df,\n",
    "    on=\"merchant_category\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Final dataset preview\n",
    "print(final_df.head())\n",
    "print(final_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7564fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(\n",
    "    df_txn_customer,\n",
    "    merchants_df,\n",
    "    on=\"merchant_category\",\n",
    "    how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8740a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"final_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e38fbefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bebfc1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38413, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d85afd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchants_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46dc1beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bab1d3",
   "metadata": {},
   "source": [
    "***Confirm Data Integrity***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6af99eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   transaction_id          50000 non-null  object        \n",
      " 1   transaction_date        50000 non-null  datetime64[ns]\n",
      " 2   customer_id             50000 non-null  object        \n",
      " 3   merchant_category       50000 non-null  object        \n",
      " 4   transaction_amount      50000 non-null  float64       \n",
      " 5   transaction_type        50000 non-null  object        \n",
      " 6   merchant_country_x      50000 non-null  object        \n",
      " 7   hours_since_last_txn    50000 non-null  float64       \n",
      " 8   is_foreign_transaction  50000 non-null  int64         \n",
      " 9   fraud_risk_score        50000 non-null  float64       \n",
      " 10  is_fraud                50000 non-null  int64         \n",
      " 11  age                     50000 non-null  int64         \n",
      " 12  income_band             50000 non-null  object        \n",
      " 13  credit_score            50000 non-null  int64         \n",
      " 14  customer_since          50000 non-null  object        \n",
      " 15  home_country            50000 non-null  object        \n",
      " 16  risk_segment            50000 non-null  object        \n",
      " 17  merchant_country_y      50000 non-null  object        \n",
      " 18  avg_transaction_value   50000 non-null  float64       \n",
      " 19  merchant_risk_score     50000 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(5), int64(4), object(10)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "final_df.shape\n",
    "final_df.isnull().sum()\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcebeb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['is_foreign_transaction', 'is_fraud', 'age', 'credit_score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "int_col = final_df.select_dtypes(include='int64').columns\n",
    "print(int_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ab88512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['transaction_id', 'customer_id', 'merchant_category',\n",
      "       'transaction_type', 'merchant_country_x', 'income_band',\n",
      "       'customer_since', 'home_country', 'risk_segment', 'merchant_country_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "obj_col = final_df.select_dtypes(include='object').columns\n",
    "print(obj_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc10331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3319)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 3319 entries, transaction_id to merchant_country_y_UAE\n",
      "dtypes: bool(3307), datetime64[ns](1), float64(5), int64(4), object(2)\n",
      "memory usage: 162.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Identify object columns to encode (exclude identifiers)\n",
    "# Identifiers like transaction_id and customer_id shouldn't be one-hot encoded\n",
    "object_cols = final_df.select_dtypes(include='object').columns\n",
    "cols_to_encode = [col for col in object_cols if col not in ['transaction_id', 'customer_id']]\n",
    "\n",
    "# Step 2: Apply One-Hot Encoding only to categorical features\n",
    "final_df_ohe = pd.get_dummies(\n",
    "    final_df,\n",
    "    columns=cols_to_encode,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# Step 3: Sanity check\n",
    "print(final_df_ohe.shape)\n",
    "final_df_ohe.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89b83ac",
   "metadata": {},
   "source": [
    "*Another Way*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69a6967a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 3317 entries, transaction_date to merchant_country_y_UAE\n",
      "dtypes: bool(3307), datetime64[ns](1), float64(5), int64(4)\n",
      "memory usage: 161.5 MB\n"
     ]
    }
   ],
   "source": [
    "# 1) IDs drop karo (modeling dataset se)\n",
    "final_df_model = final_df.drop(columns=['transaction_id', 'customer_id'])\n",
    "\n",
    "# 2) Sirf real categorical (object) columns identify karo\n",
    "cat_cols = final_df_model.select_dtypes(include='object').columns\n",
    "\n",
    "# 3) One-Hot Encoding apply karo\n",
    "final_df_model = pd.get_dummies(\n",
    "    final_df_model,\n",
    "    columns=cat_cols,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# 4) Sanity checks\n",
    "final_df_model.shape\n",
    "final_df_model.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79cc2582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_model.isnull().sum().max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "980f4d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fraud\n",
       "0    96.468\n",
       "1     3.532\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check karo ki is_fraud abhi bhi same hai.\n",
    "final_df_model['is_fraud'].value_counts(normalize=True) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1794ed72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_model.select_dtypes(include='object').columns\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
