{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58766b6",
   "metadata": {},
   "source": [
    "********Generate Dataset********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17530eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 11)\n",
      "is_fraud\n",
      "0    0.96468\n",
      "1    0.03532\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "\n",
    "# -----------------------\n",
    "# Setup\n",
    "# -----------------------\n",
    "fake = Faker()\n",
    "np.random.seed(42)\n",
    "Faker.seed(42)\n",
    "\n",
    "ROWS = 50000\n",
    "FRAUD_RATE = 0.035\n",
    "\n",
    "merchant_categories = [\n",
    "    \"Grocery\", \"Fuel\", \"Electronics\",\n",
    "    \"Travel\", \"Dining\", \"E-commerce\"\n",
    "]\n",
    "\n",
    "transaction_types = [\"Online\", \"POS\", \"ATM\"]\n",
    "countries = [\"India\", \"USA\", \"UK\", \"UAE\", \"Singapore\"]\n",
    "\n",
    "records = []\n",
    "\n",
    "# -----------------------\n",
    "# Data Generation Loop\n",
    "# -----------------------\n",
    "for _ in range(ROWS):\n",
    "\n",
    "    # Fraud flag\n",
    "    is_fraud = np.random.choice([0, 1], p=[1 - FRAUD_RATE, FRAUD_RATE])\n",
    "\n",
    "    # Transaction amount\n",
    "    amount = (\n",
    "        np.random.normal(2500, 1200)\n",
    "        if is_fraud == 0\n",
    "        else np.random.uniform(8000, 50000)\n",
    "    )\n",
    "\n",
    "    # Time gap (velocity)\n",
    "    hours_gap = (\n",
    "        np.random.exponential(10)\n",
    "        if is_fraud == 0\n",
    "        else np.random.uniform(0.1, 1.5)\n",
    "    )\n",
    "\n",
    "    # Foreign transaction flag\n",
    "    foreign_txn = (\n",
    "        np.random.choice([0, 1], p=[0.85, 0.15])\n",
    "        if is_fraud == 0\n",
    "        else np.random.choice([0, 1], p=[0.3, 0.7])\n",
    "    )\n",
    "\n",
    "    # Risk score\n",
    "    risk_score = round(\n",
    "        (amount / 50000) * 0.4 +\n",
    "        (1 / max(hours_gap, 0.1)) * 0.4 +\n",
    "        foreign_txn * 0.2,\n",
    "        2\n",
    "    )\n",
    "\n",
    "    # Append record\n",
    "    records.append({\n",
    "        \"transaction_id\": fake.uuid4(),\n",
    "        \"transaction_date\": fake.date_time_between(\"-6M\", \"now\"),\n",
    "        \"customer_id\": f\"CUST-{np.random.randint(10000, 99999)}\",\n",
    "        \"merchant_category\": np.random.choice(merchant_categories),\n",
    "        \"transaction_amount\": round(max(amount, 50), 2),\n",
    "        \"transaction_type\": np.random.choice(transaction_types),\n",
    "        \"merchant_country\": np.random.choice(countries),\n",
    "        \"hours_since_last_txn\": round(hours_gap, 2),\n",
    "        \"is_foreign_transaction\": foreign_txn,\n",
    "        \"fraud_risk_score\": risk_score,\n",
    "        \"is_fraud\": is_fraud\n",
    "    })\n",
    "\n",
    "# -----------------------\n",
    "# Create DataFrame & Save\n",
    "# -----------------------\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(\"transactions.csv\", index=False)\n",
    "\n",
    "print(df.shape)\n",
    "print(df[\"is_fraud\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab620cb",
   "metadata": {},
   "source": [
    "*Customer Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aaf711f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38413, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>age</th>\n",
       "      <th>income_band</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>customer_since</th>\n",
       "      <th>home_country</th>\n",
       "      <th>risk_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUST-54131</td>\n",
       "      <td>56</td>\n",
       "      <td>Medium</td>\n",
       "      <td>564</td>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>USA</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUST-93104</td>\n",
       "      <td>38</td>\n",
       "      <td>Low</td>\n",
       "      <td>514</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>India</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUST-28431</td>\n",
       "      <td>41</td>\n",
       "      <td>Low</td>\n",
       "      <td>451</td>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>USA</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUST-90038</td>\n",
       "      <td>19</td>\n",
       "      <td>Medium</td>\n",
       "      <td>707</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>India</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUST-33483</td>\n",
       "      <td>38</td>\n",
       "      <td>Medium</td>\n",
       "      <td>607</td>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>India</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  age income_band  credit_score customer_since home_country  \\\n",
       "0  CUST-54131   56      Medium           564     2020-02-10          USA   \n",
       "1  CUST-93104   38         Low           514     2020-02-28        India   \n",
       "2  CUST-28431   41         Low           451     2020-01-19          USA   \n",
       "3  CUST-90038   19      Medium           707     2022-06-30        India   \n",
       "4  CUST-33483   38      Medium           607     2018-08-28        India   \n",
       "\n",
       "  risk_segment  \n",
       "0       Medium  \n",
       "1         High  \n",
       "2         High  \n",
       "3          Low  \n",
       "4       Medium  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "np.random.seed(42)\n",
    "\n",
    "# --------------------------------\n",
    "# Step 1: Transactions se unique customer_id nikaalna\n",
    "# --------------------------------\n",
    "# Kyun: Customers dataset ko transactions se link karna hai\n",
    "customer_ids = df[\"customer_id\"].unique()\n",
    "\n",
    "# --------------------------------\n",
    "# Step 2: Empty list banani (records store karne ke liye)\n",
    "# --------------------------------\n",
    "customer_records = []\n",
    "\n",
    "# --------------------------------\n",
    "# Step 3: Har customer ke liye profile banana\n",
    "# --------------------------------\n",
    "for cust_id in customer_ids:\n",
    "\n",
    "    # Age generate karna (realistic banking range)\n",
    "    age = np.random.randint(18, 70)\n",
    "\n",
    "    # Income band decide karna (simple segmentation)\n",
    "    income_band = np.random.choice(\n",
    "        [\"Low\", \"Medium\", \"High\"],\n",
    "        p=[0.4, 0.4, 0.2]   # zyada log low/medium income hote hain\n",
    "    )\n",
    "\n",
    "    # Credit score generate karna\n",
    "    credit_score = (\n",
    "        np.random.randint(300, 600) if income_band == \"Low\"\n",
    "        else np.random.randint(550, 750) if income_band == \"Medium\"\n",
    "        else np.random.randint(700, 900)\n",
    "    )\n",
    "    # Low income → low credit score, High income → better score\n",
    "\n",
    "    # Customer since date (kab se bank ka customer hai)\n",
    "    customer_since = fake.date_between(start_date=\"-10y\", end_date=\"-1y\")\n",
    "\n",
    "    # Home country\n",
    "    home_country = np.random.choice(\n",
    "        [\"India\", \"USA\", \"UK\", \"UAE\", \"Singapore\"],\n",
    "        p=[0.6, 0.15, 0.1, 0.1, 0.05]\n",
    "    )\n",
    "\n",
    "    # Risk segment derive karna (business-friendly label)\n",
    "    if credit_score < 550:\n",
    "        risk_segment = \"High\"\n",
    "    elif credit_score < 700:\n",
    "        risk_segment = \"Medium\"\n",
    "    else:\n",
    "        risk_segment = \"Low\"\n",
    "\n",
    "    # --------------------------------\n",
    "    # Step 4: Customer record append karna\n",
    "    # --------------------------------\n",
    "    customer_records.append({\n",
    "        \"customer_id\": cust_id,\n",
    "        \"age\": age,\n",
    "        \"income_band\": income_band,\n",
    "        \"credit_score\": credit_score,\n",
    "        \"customer_since\": customer_since,\n",
    "        \"home_country\": home_country,\n",
    "        \"risk_segment\": risk_segment\n",
    "    })\n",
    "\n",
    "# --------------------------------\n",
    "# Step 5: DataFrame banana\n",
    "# --------------------------------\n",
    "customers_df = pd.DataFrame(customer_records)\n",
    "\n",
    "# --------------------------------\n",
    "# Step 6: CSV me save karna\n",
    "# --------------------------------\n",
    "customers_df.to_csv(\"customers.csv\", index=False)\n",
    "\n",
    "# Quick sanity check\n",
    "print(customers_df.shape)\n",
    "customers_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069ad65",
   "metadata": {},
   "source": [
    "*Merchants Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "481a3b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_category</th>\n",
       "      <th>merchant_country</th>\n",
       "      <th>avg_transaction_value</th>\n",
       "      <th>merchant_risk_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2185.43</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Travel</td>\n",
       "      <td>India</td>\n",
       "      <td>3193.96</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuel</td>\n",
       "      <td>UAE</td>\n",
       "      <td>761.38</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E-commerce</td>\n",
       "      <td>India</td>\n",
       "      <td>3686.33</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dining</td>\n",
       "      <td>India</td>\n",
       "      <td>4245.99</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  merchant_category merchant_country  avg_transaction_value  \\\n",
       "0       Electronics        Singapore                2185.43   \n",
       "1            Travel            India                3193.96   \n",
       "2              Fuel              UAE                 761.38   \n",
       "3        E-commerce            India                3686.33   \n",
       "4            Dining            India                4245.99   \n",
       "\n",
       "   merchant_risk_score  \n",
       "0                 0.56  \n",
       "1                 0.45  \n",
       "2                 0.33  \n",
       "3                 0.83  \n",
       "4                 0.58  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# --------------------------------\n",
    "# Step 1: Transactions se unique merchant_category nikaalna\n",
    "# --------------------------------\n",
    "# Kyun: Merchants ko transactions se link karna hai\n",
    "merchant_categories = df[\"merchant_category\"].unique()\n",
    "\n",
    "# --------------------------------\n",
    "# Step 2: Empty list banani (merchant records store karne ke liye)\n",
    "# --------------------------------\n",
    "merchant_records = []\n",
    "\n",
    "# --------------------------------\n",
    "# Step 3: Har merchant category ke liye profile banana\n",
    "# --------------------------------\n",
    "for category in merchant_categories:\n",
    "\n",
    "    # Average transaction value (category-specific behavior)\n",
    "    avg_txn_value = np.random.uniform(500, 5000)\n",
    "    # Grocery/Fuel jaise categories lower, Travel/Electronics higher ho sakte hain\n",
    "\n",
    "    # Merchant country (mostly domestic, thoda foreign mix)\n",
    "    merchant_country = np.random.choice(\n",
    "        [\"India\", \"USA\", \"UK\", \"UAE\", \"Singapore\"],\n",
    "        p=[0.55, 0.15, 0.1, 0.1, 0.1]\n",
    "    )\n",
    "\n",
    "    # Merchant risk score (0–1 scale)\n",
    "    merchant_risk_score = round(\n",
    "        (avg_txn_value / 5000) * 0.6 +\n",
    "        np.random.uniform(0, 0.4),\n",
    "        2\n",
    "    )\n",
    "    # High avg value + randomness = higher risk\n",
    "\n",
    "    # --------------------------------\n",
    "    # Step 4: Merchant record append karna\n",
    "    # --------------------------------\n",
    "    merchant_records.append({\n",
    "        \"merchant_category\": category,\n",
    "        \"merchant_country\": merchant_country,\n",
    "        \"avg_transaction_value\": round(avg_txn_value, 2),\n",
    "        \"merchant_risk_score\": merchant_risk_score\n",
    "    })\n",
    "\n",
    "# --------------------------------\n",
    "# Step 5: DataFrame banana\n",
    "# --------------------------------\n",
    "merchants_df = pd.DataFrame(merchant_records)\n",
    "\n",
    "# --------------------------------\n",
    "# Step 6: CSV me save karna\n",
    "# --------------------------------\n",
    "merchants_df.to_csv(\"merchants.csv\", index=False)\n",
    "\n",
    "# Quick sanity check\n",
    "print(merchants_df.shape)\n",
    "merchants_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f356f29",
   "metadata": {},
   "source": [
    "*Left-Join*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c878032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         transaction_id    transaction_date customer_id  \\\n",
      "0  bdd640fb-0667-4ad1-9c80-317fa3b1799d 2025-08-17 18:49:33  CUST-54131   \n",
      "1  bc8960a9-23b8-41e9-b924-56de3eb13b90 2025-07-15 06:45:30  CUST-93104   \n",
      "2  8b9d2434-e465-4150-bd9c-66b3ad3c2d6d 2025-07-12 06:15:38  CUST-28431   \n",
      "3  07a0ca6e-0822-48f3-ac03-1199972a8469 2025-07-13 13:44:52  CUST-90038   \n",
      "4  9a1de644-815e-46d1-bb8f-aa1837f8a88b 2025-06-30 12:45:46  CUST-33483   \n",
      "\n",
      "  merchant_category  transaction_amount transaction_type merchant_country  \\\n",
      "0       Electronics             1165.74              POS        Singapore   \n",
      "1            Travel            42962.59              POS        Singapore   \n",
      "2            Travel             2882.68              ATM               UK   \n",
      "3              Fuel             2470.65           Online              UAE   \n",
      "4            Travel             2926.66           Online               UK   \n",
      "\n",
      "   hours_since_last_txn  is_foreign_transaction  fraud_risk_score  is_fraud  \\\n",
      "0                  1.70                       0              0.25         0   \n",
      "1                  0.40                       0              1.35         1   \n",
      "2                  3.44                       0              0.14         0   \n",
      "3                 19.66                       0              0.04         0   \n",
      "4                  4.87                       0              0.11         0   \n",
      "\n",
      "   age income_band  credit_score customer_since home_country risk_segment  \n",
      "0   56      Medium           564     2020-02-10          USA       Medium  \n",
      "1   38         Low           514     2020-02-28        India         High  \n",
      "2   41         Low           451     2020-01-19          USA         High  \n",
      "3   19      Medium           707     2022-06-30        India          Low  \n",
      "4   38      Medium           607     2018-08-28        India       Medium  \n",
      "(50000, 17)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'merchants_ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_26788\\4225642023.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Check output\u001b[39;00m\n\u001b[32m     12\u001b[39m print(df_txn_customer.head())\n\u001b[32m     13\u001b[39m print(df_txn_customer.shape)\n\u001b[32m     14\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m final_df = pd.merge(\n\u001b[32m     16\u001b[39m     df_txn_customer,\n\u001b[32m     17\u001b[39m     merchants_df,\n\u001b[32m     18\u001b[39m     on=\u001b[33m\"merchants_ID\"\u001b[39m,\n",
      "\u001b[32mc:\\Users\\manju\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32mc:\\Users\\manju\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32mc:\\Users\\manju\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1294\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1295\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1296\u001b[39m                         rk = cast(Hashable, rk)\n\u001b[32m   1297\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m                             right_keys.append(right._get_label_or_level_values(rk))\n\u001b[32m   1299\u001b[39m                         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1300\u001b[39m                             \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[32m   1301\u001b[39m                             right_keys.append(right.index._values)\n",
      "\u001b[32mc:\\Users\\manju\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1910\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1911\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1912\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1913\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1915\u001b[39m \n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1917\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'merchants_ID'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# LEFT JOIN because every transaction is important\n",
    "df_txn_customer = pd.merge(\n",
    "    df,\n",
    "    customers_df,\n",
    "    on=\"customer_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Check output\n",
    "print(df_txn_customer.head())\n",
    "print(df_txn_customer.shape)\n",
    "\n",
    "final_df = pd.merge(\n",
    "    df_txn_customer,\n",
    "    merchants_df,\n",
    "    on=\"merchants_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Final dataset preview\n",
    "print(final_df.head())\n",
    "print(final_df.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
